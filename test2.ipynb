{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def create_knowledge_base(pdf_path):\n",
    "  # Load PDF text\n",
    "  loader = PyPDFLoader(pdf_path, glob=\"*.pdf\")\n",
    "  text_data = loader.load()\n",
    "\n",
    "  # Text processing and chunking\n",
    "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "  text_chunks = text_splitter.split_documents(text_data)\n",
    "\n",
    "  # Download Llama2 embeddings (or your chosen model)\n",
    "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "  # Generate embeddings for each text chunk\n",
    "  # ... (code to generate embeddings for each chunk using embeddings object)\n",
    "\n",
    "  # Store text chunks and embeddings in a data structure (e.g., list of dictionaries)\n",
    "  knowledge_base = []\n",
    "  for i, chunk in enumerate(text_chunks):\n",
    "    chunk_embedding = embeddings.encode(chunk)  # Generate embedding for the chunk\n",
    "    knowledge_base.append({\n",
    "      \"text\": chunk,\n",
    "      \"embedding\": chunk_embedding\n",
    "    })\n",
    "  return knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"3c244373-c13c-4b8b-b49f-bd47d2701f47\"\n",
    "PINECONE_API_ENV = \"us-east-1-gcp-free\"\n",
    "PINECONE_INDEX_NAME = \"chatbot-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\anaconda3\\envs\\bot3\\lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone.data.index import Index\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "def store_knowledge_base_in_pinecone(knowledge_base):\n",
    "  load_dotenv()\n",
    "  PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "  PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "  PINECONE_INDEX_NAME = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "  # Connect to Pinecone\n",
    "  pc = pinecone.Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "  index = pc.Index(PINECONE_INDEX_NAME)\n",
    "\n",
    "  # Extract text and embeddings from knowledge base\n",
    "  text_data = [kb[\"text\"] for kb in knowledge_base]\n",
    "  embeddings = [kb[\"embedding\"] for kb in knowledge_base]\n",
    "\n",
    "  # Store embeddings in Pinecone\n",
    "  PineconeVectorStore.from_documents(text_data, embeddings, index_name=PINECONE_INDEX_NAME)\n",
    "\n",
    "  print(f\"Knowledge base stored in Pinecone index: {PINECONE_INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is a placeholder as the full chatbot development requires additional libraries\n",
    "# like Rasa or Dialogflow. Here's a basic outline to illustrate the concept.\n",
    "\n",
    "def chatbot_loop():\n",
    "  while True:\n",
    "    user_query = input(\"Ask me a medical question (or type 'quit' to exit): \")\n",
    "    if user_query.lower() == \"quit\":\n",
    "      break\n",
    "\n",
    "    # Process user query (similar to text processing in knowledge base creation)\n",
    "    processed_query =user_query # (code to clean and process the user query)\n",
    "\n",
    "    # Generate embedding for the user query\n",
    "    query_embedding = embeddings.encode(processed_query)\n",
    "\n",
    "    # Retrieve similar text snippets from Pinecone using query embedding\n",
    "    similar_results = retrieve_from_pinecone(query_embedding)\n",
    "\n",
    "    # Extract and present relevant information to the user\n",
    "    if similar_results:\n",
    "      for result in similar_results:\n",
    "        print(f\"Relevant Information: {result['text']}\")\n",
    "    else:\n",
    "      print(\"Sorry, I couldn't find any information related to your question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
